{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "dabfea76-b93b-4efe-b6e4-0f0b678a936b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "!ls hyperliquid/utils/kafka_callbacks.py\n",
    "!ls hyperliquid/utils/rate_limiter.py\n",
    "!ls hyperliquid/utils/example_utils.py\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "0dabe7b6-0174-4f4d-ac1e-0239efcdbe43",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "!pip install aiokafka\n",
    "!pip install kafka-python\n",
    "dbutils.library.restartPython()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "46707a82-8e7a-447f-aabe-d819e4d1386e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "import asyncio\n",
    "from asyncio import run_coroutine_threadsafe\n",
    "import os\n",
    "import json\n",
    "from datetime import datetime\n",
    "from typing import Any\n",
    "\n",
    "from hyperliquid.utils import constants\n",
    "from hyperliquid.utils import rate_limiter\n",
    "from hyperliquid.utils import example_utils\n",
    "\n",
    "from kafka import KafkaAdminClient\n",
    "from kafka.admin import NewTopic\n",
    "from kafka.errors import TopicAlreadyExistsError\n",
    "\n",
    "# Import our Kafka callbacks\n",
    "from hyperliquid.utils.kafka_callbacks import (\n",
    "    ClickHouseFillKafka,\n",
    "    ClickHouseOrderKafka,\n",
    "    ClickHouseLiquidationsKafka,\n",
    "    ClickHouseLiquidationsDevKafka\n",
    ")\n",
    "\n",
    "import yaml\n",
    "import time\n",
    "USE_DEV = True\n",
    "start_time = int(time.time() * 1000)\n",
    "\n",
    "def load_addresses_from_config(path=\"config_whales.yml\") -> list[str]:\n",
    "    try:\n",
    "        with open(path, \"r\") as f:\n",
    "            data = yaml.safe_load(f)\n",
    "            print(f\"Loaded addresses from {path}: {data}\")\n",
    "            return data.get(\"addresses\", [])\n",
    "    except Exception as e:\n",
    "        print(f\"[ERROR] Failed to load addresses from {path}: {e}\")\n",
    "        return []\n",
    "\n",
    "\n",
    "# Set up your Kafka config\n",
    "KAFKA_SERVER = \"cthki8qfdq8asdnsm9gg.any.us-east-1.mpx.prd.cloud.redpanda.com:9092\"\n",
    "USERNAME = \"alexei.jobfinder@gmail.com\"\n",
    "PASSWORD = \"y0obC7dFiU3CJxcsCH4RwXtwEhaauf\"\n",
    "username = \"alexei.jobfinder@gmail.com\"\n",
    "password = 'y0obC7dFiU3CJxcsCH4RwXtwEhaauf'\n",
    "bootstrap_servers = 'cthki8qfdq8asdnsm9gg.any.us-east-1.mpx.prd.cloud.redpanda.com:9092'\n",
    "\n",
    "# Instantiate the fill/order Kafka callbacks\n",
    "fill_kafka_cb = ClickHouseFillKafka(\n",
    "    bootstrap=KAFKA_SERVER,\n",
    "    username=USERNAME,\n",
    "    password=PASSWORD\n",
    ")\n",
    "\n",
    "order_kafka_cb = ClickHouseOrderKafka(\n",
    "    bootstrap=KAFKA_SERVER,\n",
    "    username=USERNAME,\n",
    "    password=PASSWORD\n",
    ")\n",
    "if USE_DEV:\n",
    "    liquidation_kafka_cb = ClickHouseLiquidationsDevKafka(\n",
    "        bootstrap=KAFKA_SERVER,\n",
    "        username=USERNAME,\n",
    "        password=PASSWORD\n",
    "    )\n",
    "else:\n",
    "    liquidation_kafka_cb = ClickHouseLiquidationsKafka(\n",
    "        bootstrap=KAFKA_SERVER,\n",
    "        username=USERNAME,\n",
    "        password=PASSWORD\n",
    "    )\n",
    "\n",
    "\n",
    "rate_limiter = rate_limiter.HyperliquidRateLimiter()\n",
    "event_loop = asyncio.get_event_loop()\n",
    "\n",
    "\n",
    "def ensure_topics(bootstrap_servers, username, password, sasl_mechanism=\"SCRAM-SHA-256\"):\n",
    "    admin = KafkaAdminClient(\n",
    "        bootstrap_servers=bootstrap_servers,\n",
    "        security_protocol=\"SASL_SSL\",\n",
    "        sasl_mechanism=sasl_mechanism,\n",
    "        sasl_plain_username=username,\n",
    "        sasl_plain_password=password,\n",
    "    )\n",
    "\n",
    "    topics_to_create = [\n",
    "        'orders',\n",
    "        'fills',\n",
    "        'liquidations_dev',\n",
    "    ]\n",
    "\n",
    "    existing_topics = admin.list_topics()\n",
    "\n",
    "    new_topics = []\n",
    "    for t in topics_to_create:\n",
    "        if t not in existing_topics:\n",
    "            new_topics.append(NewTopic(name=t, num_partitions=1, replication_factor=3))\n",
    "\n",
    "    if new_topics:\n",
    "        try:\n",
    "            admin.create_topics(new_topics=new_topics)\n",
    "            print(\"Created topics:\", [nt.name for nt in new_topics])\n",
    "        except TopicAlreadyExistsError:\n",
    "            print(\"Some topics already exist.\")\n",
    "    else:\n",
    "        print(\"All topics already exist\")\n",
    "\n",
    "    admin.close()\n",
    "\n",
    "\n",
    "# async def handle_user_fills(msg, address):\n",
    "#     # Rate limit for each fill event.\n",
    "#     await rate_limiter.acquire_address_action(address)\n",
    "\n",
    "#     fills = msg.get(\"data\", {}).get(\"fills\", [])\n",
    "#     for f in fills:\n",
    "#         # Prepare fill data for Kafka\n",
    "#         fill_data = {\n",
    "#             \"exchange\": \"hyperliquid\",\n",
    "#             \"symbol\": f.get(\"coin\"),         # was \"coin\" in the original fill\n",
    "#             \"side\": f.get(\"side\"),\n",
    "#             \"price\": f.get(\"px\"),\n",
    "#             \"amount\": f.get(\"sz\"),\n",
    "#             \"fee\": f.get(\"fee\"),\n",
    "#             \"id\": f.get(\"hash\"),\n",
    "#             \"order_id\": f.get(\"oid\"),\n",
    "#             \"liquidity\": f.get(\"crossed\"),   # optional choice if you'd like to store \"crossed\" under liquidity\n",
    "#             \"type\": f.get(\"dir\"),\n",
    "#             \"account\": address,\n",
    "#             \"timestamp\": f.get(\"time\"),\n",
    "#             # If desired, you can provide a receipt_timestamp. Here, we omit it or set to None.\n",
    "#             \"raw\": f,                       # store the individual fill as raw\n",
    "#             \"raw_data\": msg                 # store the entire message for debugging\n",
    "#         }\n",
    "#         # Send fill data to Kafka\n",
    "#         await fill_kafka_cb.write(fill_data)\n",
    "\n",
    "\n",
    "# Notation reference for Hyperliquid v0 API (nonstandard; subject to change in v1):\n",
    "# Px   = Price\n",
    "# Sz   = Size (in units of coin, i.e., base currency)\n",
    "# Szi  = Signed size (positive for long, negative for short)\n",
    "# Ntl  = Notional (USD amount, Px * Sz)\n",
    "# Side = Side of trade/book: B = Bid = Buy, A = Ask = Short (aggressing side for trades)\n",
    "# Asset = Integer representing the asset being traded\n",
    "# Tif  = Time in force: GTC = Good 'til canceled, ALO = Add liquidity only, IOC = Immediate or cancel\n",
    "async def handle_user_fills(msg, address):\n",
    "    # Rate limit once for the batch of fills\n",
    "    await rate_limiter.acquire_address_action(address)\n",
    "    #     {\\\"coin\\\":\\\"BTC\\\",\\\"px\\\":\\\"79823.0\\\",\\\"sz\\\":\\\"0.01126\\\",\\\"side\\\":\\\"A\\\",\\\"time\\\":1743963674808,\\\"startPosition\\\":\\\"0.01126\\\",\\\"dir\\\":\\\"Close Long\\\",\\\"closedPnl\\\":\\\"-6.768386\\\",\\\"hash\\\":\\\"0x766b22d7a6c15f8f4fef0421080ab00203730023705d3dd217a1dbfe8f96a41e\\\",\\\"oid\\\":84299475887,\\\"crossed\\\":true,\\\"fee\\\":\\\"0.224701\\\",\\\"tid\\\":602065776560497,\\\"liquidation\\\":{\\\"liquidatedUser\\\":\\\"0xa44481a6454f4fd0899e261aa941323f2b11a09b\\\",\\\"markPx\\\":\\\"79840.0\\\",\\\"method\\\":\\\"market\\\"},\\\"feeToken\\\":\\\"USDC\\\"},\n",
    "    fills = msg.get(\"data\", {}).get(\"fills\", [])\n",
    "    for f in fills:\n",
    "        try:\n",
    "            ts = f.get(\"time\")\n",
    "            # Extract liquidation info\n",
    "            liquidation = f.get(\"liquidation\", {}) or {}\n",
    "            is_liquidation = 1 if liquidation else 0\n",
    "            liquidated_user = liquidation.get(\"liquidatedUser\") if is_liquidation else -1\n",
    "            liquidation_method = liquidation.get(\"method\") if is_liquidation else None\n",
    "            liquidation_mark_price = liquidation.get(\"markPx\") if is_liquidation else -1\n",
    "            side = f.get(\"side\")\n",
    "            normalized_side = {\"B\": \"buy\", \"A\": \"sell\"}.get(side, side)  # Normalize side to 'buy'/'sell'\n",
    "            # create a hash of f\n",
    "            fill_data = {\n",
    "                \"exchange\": \"hyperliquid\",\n",
    "                \"symbol\": f.get(\"coin\"),\n",
    "                \"side\": normalized_side,\n",
    "                \"price\": f.get(\"px\"),\n",
    "                \"amount\": f.get(\"sz\"),\n",
    "                \"fee\": f.get(\"fee\"),\n",
    "                \"id\": f.get(\"hash\"), # i can dedup by id which is the hash of the fill\n",
    "                \"order_id\": f.get(\"oid\"),\n",
    "                \"liquidity\": f.get(\"crossed\"),\n",
    "                \"type\": f.get(\"dir\"),\n",
    "                \"account\": address,\n",
    "                \"timestamp\": ts,\n",
    "                \"is_liquidation\": is_liquidation,\n",
    "                \"liquidated_user\": liquidated_user,\n",
    "                \"liquidation_method\": liquidation_method,\n",
    "                \"liquidation_mark_price\": liquidation_mark_price,\n",
    "                # the price that the book reached when the order was sent for liquidation\n",
    "                # the price is what it actually executed at. \n",
    "                # e.g. mark price was 108.69, so book reached that\n",
    "                # but executed at 108.51\n",
    "                \"raw\": f,\n",
    "                \"raw_data\": f\n",
    "            }\n",
    "            print(f\"[DEBUG] Fills data for address {address}: {fill_data}\")\n",
    "            await fill_kafka_cb.write(fill_data)\n",
    "\n",
    "            if is_liquidation:\n",
    "                data = {\n",
    "                    \"exchange\": \"hyperliquid\",\n",
    "                    \"symbol\": f.get(\"coin\"),\n",
    "                    \"side\": normalized_side,\n",
    "                    \"quantity\": f.get(\"sz\"),\n",
    "                    \"price\": f.get(\"px\"),\n",
    "                    \"id\": f.get(\"hash\"), # i can dedup by id which is the hash of the fill\n",
    "                    \"status\": f.get(\"dir\"),\n",
    "                    \"timestamp\": ts,\n",
    "                    \"is_liquidation\": is_liquidation,\n",
    "                    \"liquidated_user\": liquidated_user,\n",
    "                    \"liquidation_method\": liquidation_method,\n",
    "                    \"liquidation_mark_price\": liquidation_mark_price,\n",
    "                    \"raw\": f,\n",
    "                    \"raw_data\": f,\n",
    "                }\n",
    "                await liquidation_kafka_cb.write(data)\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"[WARN] Failed to process fill for address {address}: {e}\")\n",
    "\n",
    "async def handle_order_updates(msg, address):\n",
    "    # Rate limit for each order update.\n",
    "    await rate_limiter.acquire_address_action(address)\n",
    "\n",
    "    for update in msg.get(\"data\", []):\n",
    "        order = update.get(\"order\", {})\n",
    "        side = order.get(\"side\")\n",
    "        normalized_side = {\"B\": \"buy\", \"A\": \"sell\"}.get(side, side)\n",
    "\n",
    "        # Compute remaining amount if both origSz and sz are available\n",
    "        try:\n",
    "            orig_sz = float(order.get(\"origSz\", \"nan\"))\n",
    "            current_sz = float(order.get(\"sz\", \"nan\"))\n",
    "            remaining_amount = orig_sz - current_sz\n",
    "        except Exception:\n",
    "            remaining_amount = None  # fallback if values are missing or invalid\n",
    "\n",
    "        order_data = {\n",
    "            \"exchange\": \"hyperliquid\",\n",
    "            \"symbol\": order.get(\"coin\"),\n",
    "            \"id\": order.get(\"oid\"),\n",
    "            \"client_order_id\": order.get(\"cloid\"),\n",
    "            \"side\": normalized_side,\n",
    "            \"status\": update.get(\"status\"),\n",
    "            \"type\": \"limit\" if order.get(\"limitPx\") else \"unknown\",\n",
    "            \"price\": order.get(\"limitPx\"),\n",
    "            \"amount\": order.get(\"sz\"),\n",
    "            \"remaining_amount\": str(remaining_amount) if remaining_amount is not None else None,\n",
    "            \"timestamp\": order.get(\"timestamp\"),\n",
    "            \"account\": address,\n",
    "            \"raw\": order,\n",
    "            \"raw_data\": msg\n",
    "        }\n",
    "\n",
    "        print(f\"[DEBUG] order_data for address {address}: {order_data}\")\n",
    "        await order_kafka_cb.write(order_data)\n",
    "\n",
    "\n",
    "async def backfill_fills(address: str, _start_time: int):\n",
    "    _, info, _ = example_utils.setup(constants.MAINNET_API_URL)\n",
    "\n",
    "    # 3-day window (in milliseconds)\n",
    "    end_time = int(time.time() * 1000)\n",
    "    start_time = end_time - 7 * 86400 * 1000  # 7 days ago\n",
    "\n",
    "    seen_fill_ids: set[str] = set()\n",
    "\n",
    "    try:\n",
    "        fills = info.user_fills_by_time(address, start_time, end_time)\n",
    "        for msg in fills:\n",
    "            fill_id = msg.get(\"hash\")\n",
    "            if fill_id in seen_fill_ids:\n",
    "                continue\n",
    "            seen_fill_ids.add(fill_id)\n",
    "            await handle_user_fills({\"data\": {\"fills\": [msg]}}, address)\n",
    "            await asyncio.sleep(0.01)  # throttle per fill\n",
    "    except Exception as e:\n",
    "        print(f\"[ERROR] backfill_fills failed for {address}: {e}\")\n",
    "\n",
    "\n",
    "async def subscribe_to_address(address: str, include_backfill_fills: bool):\n",
    "    try:\n",
    "        _, info, _ = example_utils.setup(constants.MAINNET_API_URL)\n",
    "\n",
    "        await rate_limiter.acquire_address_action(address)\n",
    "\n",
    "        if include_backfill_fills:\n",
    "            await backfill_fills(address, start_time)\n",
    "\n",
    "        info.subscribe({\"type\": \"userFills\", \"user\": address},\n",
    "                       lambda msg: run_coroutine_threadsafe(handle_user_fills(msg, address), event_loop))\n",
    "        info.subscribe({\"type\": \"orderUpdates\", \"user\": address},\n",
    "                       lambda msg: run_coroutine_threadsafe(handle_order_updates(msg, address), event_loop))\n",
    "\n",
    "        print(f\"[{address}] Subscribed. Listening...\")\n",
    "\n",
    "        while True:\n",
    "            await asyncio.sleep(5)\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"[{address}] ERROR: {e}\")\n",
    "        await asyncio.sleep(3)\n",
    "        return await subscribe_to_address(address, include_backfill_fills)\n",
    "\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"[{address}] ERROR: {e}\")\n",
    "        await asyncio.sleep(3)\n",
    "        return await subscribe_to_address(address)  # Auto-retry\n",
    "\n",
    "async def main():\n",
    "    INCLUDE_BACKFILL_FILLS = True\n",
    "    ensure_topics(bootstrap_servers, username, password)\n",
    "\n",
    "    addresses = load_addresses_from_config()\n",
    "\n",
    "    BATCH_SIZE = 10\n",
    "    DELAY_BETWEEN_BATCHES = 15  # seconds\n",
    "\n",
    "    for i in range(0, len(addresses), BATCH_SIZE):\n",
    "        batch = addresses[i:i + BATCH_SIZE]\n",
    "        print(f\"[INFO] Subscribing to batch {i//BATCH_SIZE + 1} of {len(addresses)//BATCH_SIZE + 1}\")\n",
    "        await asyncio.gather(*[\n",
    "            subscribe_to_address(addr, INCLUDE_BACKFILL_FILLS)\n",
    "            for addr in batch\n",
    "        ])\n",
    "        await asyncio.sleep(DELAY_BETWEEN_BATCHES)\n",
    "\n",
    "\n",
    "# if __name__ == \"__main__\":\n",
    "#     asyncio.run(main())\n",
    "\n",
    "await main()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "ccecf908-e634-4b6e-8a22-f2b091b0ebdc",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# async def main():\n",
    "#     addresses = [\n",
    "#         \"0x0000a0ab1b620e79fa089a16c89c5eeee490f2da\",\n",
    "#         \"0x007d76eec0ba411ce873a8819df50dd443d967a0\",\n",
    "#         \"0x023a3d058020fb76cca98f01b3c48c8938a22355\",\n",
    "#         \"0x03ca2d85b85dc1d61243cc2932382dbc6285fbda\",\n",
    "#         \"0x06cecfbac34101ae41c88ebc2450f8602b3d164b\",\n",
    "#         \"0x091144e651b334341eabdbbbfed644ad0100023e\",\n",
    "#         \"0x0a170cdb6eb5a46c15cffd727c8659f2f371f478\",\n",
    "#         \"0x0a97692d91fa9195a52da81cca2051c032c5347d\",\n",
    "#     ]\n",
    "\n",
    "#     await asyncio.gather(*[subscribe_to_address(addr) for addr in addresses])\n",
    "\n",
    "# async def main():\n",
    "#     INCLUDE_BACKFILL_FILLS = True\n",
    "#     ensure_topics(bootstrap_servers, username, password, sasl_mechanism=\"SCRAM-SHA-256\")\n",
    "\n",
    "#     addresses = load_addresses_from_config()\n",
    "#     # addresses = ['0xa44481a6454f4FD0899e261Aa941323f2b11A09b']\n",
    "#     if not addresses:\n",
    "#         print(\"[WARN] No addresses found in config.\")\n",
    "#         return\n",
    "\n",
    "#     await asyncio.gather(*[\n",
    "#         subscribe_to_address(addr, INCLUDE_BACKFILL_FILLS)\n",
    "#         for addr in addresses\n",
    "#     ])"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "2"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "run_fills_orders",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
